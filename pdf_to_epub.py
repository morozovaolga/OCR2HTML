"""
–ï–¥–∏–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ—Ç PDF –∫ EPUB
–°–ª–µ–¥—É–µ—Ç —Ç–æ—á–Ω–æ–π —Å—Ö–µ–º–µ –∏–∑ PIPELINE_SCHEMA.md
"""
import argparse
import json
import os
import re
import subprocess
import sys
from pathlib import Path

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UTF-8 –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏ (Windows)
if sys.platform == 'win32':
    try:
        if hasattr(sys.stdout, 'reconfigure'):
            sys.stdout.reconfigure(encoding='utf-8')
        if hasattr(sys.stderr, 'reconfigure'):
            sys.stderr.reconfigure(encoding='utf-8')
        os.environ['PYTHONIOENCODING'] = 'utf-8'
    except Exception:
        pass


def run_cmd(cmd, description=""):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É –∏ –≤—ã–≤–æ–¥–∏—Ç –æ–ø–∏—Å–∞–Ω–∏–µ"""
    if description:
        print(f"\n{'='*80}")
        print(f"{description}")
        print(f"{'='*80}")
    print(f"$ {' '.join(cmd)}")
    try:
        subprocess.check_call(cmd)
        return True
    except subprocess.CalledProcessError as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description='–ï–¥–∏–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: PDF ‚Üí EPUB (–ø–æ —Å—Ö–µ–º–µ PIPELINE_SCHEMA.md)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

1. –ë–∞–∑–æ–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç (LanguageTool + Post-cleanup + EPUB):
   python pdf_to_epub.py --pdf book.pdf --title "–ù–∞–∑–≤–∞–Ω–∏–µ" --author "–ê–≤—Ç–æ—Ä"

2. –° –ª–æ–∫–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏:
   python pdf_to_epub.py --pdf book.pdf --title "–ù–∞–∑–≤–∞–Ω–∏–µ" --author "–ê–≤—Ç–æ—Ä" \\
     --local-spell --local-spell-type pyspellchecker

3. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:
   python pdf_to_epub.py --pdf book.pdf --title "–ù–∞–∑–≤–∞–Ω–∏–µ" --author "–ê–≤—Ç–æ—Ä" \\
     --local-spell --local-spell-type pyspellchecker \\
     --lt-cloud \\
     --context-check \\
     --epub-template sample.epub

4. –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏ –æ–±–ª–æ–∂–∫–∏:
   python pdf_to_epub.py --pdf book.pdf --title "–ù–∞–∑–≤–∞–Ω–∏–µ" --author "–ê–≤—Ç–æ—Ä" \\
     --cover-colors "#ffbe0b,#fb5607,#ff006e,#8338ec,#3a86ff"
        """
    )
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--pdf', required=True, help='–ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É')
    parser.add_argument('--outdir', default='out', help='–ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: out)')
    parser.add_argument('--title', required=True, help='–ù–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏')
    parser.add_argument('--author', default='', help='–ê–≤—Ç–æ—Ä –∫–Ω–∏–≥–∏')
    
    # –≠—Ç–∞–ø 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
    parser.add_argument('--two-columns', action='store_true', help='PDF —Å –¥–≤—É–º—è –∫–æ–ª–æ–Ω–∫–∞–º–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ')
    
    # –≠—Ç–∞–ø 2: Oldspelling (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    parser.add_argument('--no-oldspelling', action='store_true', help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª —Å—Ç–∞—Ä–æ–π –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏')
    
    # –≠—Ç–∞–ø 3: Stanza —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    parser.add_argument('--stanza-tokenize', action='store_true', help='–£–ª—É—á—à–∏—Ç—å —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Stanza')
    parser.add_argument('--stanza-model', default='', help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ Stanza (.pt —Ñ–∞–π–ª)')
    
    # –≠—Ç–∞–ø 4: –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è (–≤—Å–µ–≥–¥–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è)
    
    # –≠—Ç–∞–ø 5: –õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    parser.add_argument('--local-spell', action='store_true', help='–ü—Ä–∏–º–µ–Ω–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏')
    parser.add_argument('--local-spell-type', default='pyspellchecker', 
                       choices=['pyspellchecker', 'jamspell', 'symspell', 'auto'],
                       help='–¢–∏–ø –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≤–µ—Ä—â–∏–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: pyspellchecker)')
    parser.add_argument('--local-spell-model', default='', help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (jamspell) –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—é (symspell)')
    parser.add_argument('--local-spell-lang', default='ru', help='–Ø–∑—ã–∫ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏')
    
    # –≠—Ç–∞–ø 6: LanguageTool (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    parser.add_argument('--lt-cloud', action='store_true', help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LanguageTool (–æ–±–ª–∞—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)')
    parser.add_argument('--chunk-size', type=int, default=6000, help='–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è LanguageTool (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 6000)')
    
    # –≠—Ç–∞–ø 7: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    parser.add_argument('--context-check', action='store_true', help='–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ+–≥–ª–∞–≥–æ–ª)')
    parser.add_argument('--context-out', default='context_warnings.txt', help='–§–∞–π–ª —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏')
    parser.add_argument('--context-pronouns', default='–æ–Ω,–æ–Ω–∞,–æ–Ω–æ,–æ–Ω–∏,–º—ã,–≤—ã,—Ç—ã', help='–ú–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏')
    
    # –≠—Ç–∞–ø 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è EPUB (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    parser.add_argument('--epub-template', nargs='?', const='sample.epub', help='–ü—É—Ç—å –∫ —à–∞–±–ª–æ–Ω—É EPUB (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: sample.epub). –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç EPUB')
    parser.add_argument('--cover-colors', default='', help='–ü—è—Ç—å HEX-—Ü–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–ø–æ–ª–æ—Å–∫–∞, –≤–µ—Ä—Ö–Ω–∏–π –±–ª–æ–∫, –∑–∞–≥–æ–ª–æ–≤–æ–∫, –≥—Ä–∞–¥–∏–µ–Ω—Ç –Ω–∞—á–∞–ª–æ, –≥—Ä–∞–¥–∏–µ–Ω—Ç –∫–æ–Ω–µ—Ü)')
    parser.add_argument('--epub-max-chapter-size', type=int, default=50, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≥–ª–∞–≤—ã/—Å–µ–∫—Ü–∏–∏ –≤ KB (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 50)')
    parser.add_argument('--epub-use-chapter-heads', action='store_true', help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –≥–ª–∞–≤—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –ø—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä—É)')
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    parser.add_argument('--natasha-check', action='store_true', help='–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ Natasha')
    parser.add_argument('--natasha-types', default='PER,LOC', help='–¢–∏–ø—ã —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è Natasha (PER, LOC, ORG)')
    parser.add_argument('--natasha-out', default='natasha_diff.txt', help='–§–∞–π–ª –æ—Ç—á–µ—Ç–∞ Natasha –ø—Ä–æ–≤–µ—Ä–∫–∏')
    parser.add_argument('--natasha-sync', action='store_true', help='–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ Natasha')
    parser.add_argument('--natasha-sync-report', default='natasha_sync.txt', help='–§–∞–π–ª –æ—Ç—á–µ—Ç–∞ Natasha —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏')
    
    args = parser.parse_args()
    
    here = Path(__file__).parent
    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ PDF
    pdf_path = Path(args.pdf)
    if not pdf_path.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: PDF —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pdf_path}")
        return 1
    
    print("=" * 80)
    print("–ü–ê–ô–ü–õ–ê–ô–ù: PDF ‚Üí EPUB")
    print("=" * 80)
    print(f"PDF: {pdf_path}")
    print(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {args.title}")
    if args.author:
        print(f"–ê–≤—Ç–æ—Ä: {args.author}")
    print(f"–ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {outdir}")
    print("\n–≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    
    step_num = 1
    
    # –≠—Ç–∞–ø 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
    print(f"  {step_num}. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–∑ PDF")
    step_num += 1
    
    extract_cmd = [
        sys.executable,
        str(here / "extract_structured_text.py"),
        "--pdf", str(pdf_path),
        "--outdir", str(outdir)
    ]
    if args.two_columns:
        extract_cmd.append("--two-columns")
    
    if not run_cmd(extract_cmd, f"–≠—Ç–∞–ø 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"):
        return 1
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    structured_in = outdir / "structured.json"
    
    # –≠—Ç–∞–ø 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª oldspelling (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if not args.no_oldspelling:
        print(f"  {step_num}. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª —Å—Ç–∞—Ä–æ–π –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏")
        step_num += 1
        
        apply_cmd = [
            sys.executable,
            str(here / "apply_rules_structured.py"),
            "--rules", str(here / "oldspelling.py"),
            "--in", str(structured_in),
            "--out", str(outdir / "structured_rules.json")
        ]
        if not run_cmd(apply_cmd, f"–≠—Ç–∞–ø 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª oldspelling"):
            return 1
        
        structured_in = outdir / "structured_rules.json"
    
    # –≠—Ç–∞–ø 3: Stanza —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.stanza_tokenize and args.stanza_model:
        print(f"  {step_num}. Stanza —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è")
        step_num += 1
        
        stanza_cmd = [
            sys.executable,
            str(here / "stanza_tokenizer.py"),
            "--in", str(structured_in),
            "--out", str(outdir / "structured_tokenized.json"),
            "--model", args.stanza_model
        ]
        if not run_cmd(stanza_cmd, f"–≠—Ç–∞–ø 3: Stanza —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"):
            return 1
        
        structured_in = outdir / "structured_tokenized.json"
    
    # –≠—Ç–∞–ø 4: –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è (–≤—Å–µ–≥–¥–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è)
    print(f"  {step_num}. –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏")
    step_num += 1
    
    modernize_cmd = [
        sys.executable,
        str(here / "modernize_structured.py"),
        "--in", str(structured_in),
        "--outdir", str(outdir),
        "--title", args.title
    ]
    if not run_cmd(modernize_cmd, f"–≠—Ç–∞–ø 4: –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏"):
        return 1
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–æ–∫ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏
    spell_input = outdir / "final.txt"
    
    # –≠—Ç–∞–ø 5: –õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.local_spell:
        print(f"  {step_num}. –õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ ({args.local_spell_type})")
        step_num += 1
        
        if not spell_input.exists():
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {spell_input.name} –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –ª–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞")
        else:
            local_spell_cmd = [
                sys.executable,
                str(here / "local_spell_checker.py"),
                "--in", str(spell_input),
                "--outdir", str(outdir),
                "--title", args.title + " (Local Spell)",
                "--checker-type", args.local_spell_type,
                "--lang", args.local_spell_lang,
            ]
            if args.local_spell_model:
                if args.local_spell_type == "jamspell":
                    local_spell_cmd.extend(["--model-path", args.local_spell_model])
                elif args.local_spell_type == "symspell":
                    local_spell_cmd.extend(["--dictionary-path", args.local_spell_model])
                elif args.local_spell_type == "auto":
                    local_spell_cmd.extend(["--model-path", args.local_spell_model])
            
            if not run_cmd(local_spell_cmd, f"–≠—Ç–∞–ø 5: –õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏"):
                return 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —ç—Ç–∞–ø–∞
            local_spell_output = outdir / "final_local_spell.txt"
            if local_spell_output.exists():
                spell_input = local_spell_output
    
    # –≠—Ç–∞–ø 6: LanguageTool (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.lt_cloud:
        print(f"  {step_num}. LanguageTool –ø—Ä–æ–≤–µ—Ä–∫–∞")
        step_num += 1
        
        if not spell_input.exists():
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {spell_input.name} –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî LanguageTool –ø—Ä–æ–ø—É—â–µ–Ω")
        else:
            lt_cmd = [
                sys.executable,
                str(here / "lt_cloud.py"),
                "--in", str(spell_input),
                "--outdir", str(outdir),
                "--title", args.title + " (LT)",
                "--chunk-size", str(args.chunk_size),
            ]
            if not run_cmd(lt_cmd, f"–≠—Ç–∞–ø 6: LanguageTool –ø—Ä–æ–≤–µ—Ä–∫–∞"):
                return 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —ç—Ç–∞–ø–∞
            lt_output = outdir / "final_clean.txt"
            if lt_output.exists():
                spell_input = lt_output
    
    # –≠—Ç–∞–ø 7: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.context_check:
        print(f"  {step_num}. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
        step_num += 1
        
        context_input = outdir / "final_clean.txt"
        if not context_input.exists():
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {context_input.name} –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞")
        else:
            context_cmd = [
                sys.executable,
                str(here / "context_checker.py"),
                "--in", str(context_input),
                "--out", str(outdir / args.context_out),
                "--pronouns", args.context_pronouns
            ]
            if not run_cmd(context_cmd, f"–≠—Ç–∞–ø 7: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"):
                return 1
    
    # Natasha –ø—Ä–æ–≤–µ—Ä–∫–∏ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –ø–æ—Å–ª–µ LanguageTool)
    if args.natasha_check:
        natasha_input = outdir / "final_clean.txt"
        if natasha_input.exists():
            natasha_cmd = [
                sys.executable,
                str(here / "natasha_entity_check.py"),
                "--pdf", str(pdf_path),
                "--clean", str(natasha_input),
                "--out", str(outdir / args.natasha_out),
                "--types", args.natasha_types
            ]
            run_cmd(natasha_cmd, "Natasha –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π")
    
    if args.natasha_sync:
        natasha_input = outdir / "final_clean.txt"
        if natasha_input.exists():
            natasha_sync_cmd = [
                sys.executable,
                str(here / "natasha_sync.py"),
                "--pdf", str(pdf_path),
                "--clean", str(natasha_input),
                "--types", args.natasha_types,
                "--report", str(outdir / args.natasha_sync_report)
            ]
            run_cmd(natasha_sync_cmd, "Natasha —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π")
    
    # –≠—Ç–∞–ø 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è EPUB (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.epub_template:
        print(f"  {step_num}. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è EPUB")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è EPUB (–ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏–∑ —Å—Ö–µ–º—ã)
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: TXT (—á–∏—Å—Ç—ã–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç) > JSON (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ) > HTML (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ª–∏—à–Ω—é—é —Ä–∞–∑–º–µ—Ç–∫—É)
        epub_sources = [
            outdir / "final_clean.txt",  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤—ã—à–µ JSON
            outdir / "final.txt",
            outdir / "structured_rules.json",
            outdir / "structured.json",
            outdir / "final_clean.html",
        ]
        
        epub_source = None
        for source in epub_sources:
            if source.exists():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
                try:
                    is_valid = False
                    if source.suffix.lower() == ".txt":
                        # –î–ª—è TXT —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–∞ (–Ω–µ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã –∏ –Ω–µ —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)
                        content = source.read_text(encoding="utf-8").strip()
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç –∏ –æ–Ω –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (–º–∏–Ω–∏–º—É–º 50 —Å–∏–º–≤–æ–ª–æ–≤)
                        # –ò —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã/–ø—Ä–æ–±–µ–ª—ã
                        if content and len(content) >= 50:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –±—É–∫–≤—ã, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
                            has_letters = any(c.isalpha() for c in content)
                            is_valid = has_letters
                        else:
                            is_valid = False
                    elif source.suffix.lower() == ".json":
                        # –î–ª—è JSON —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –±–ª–æ–∫–∏
                        data = json.loads(source.read_text(encoding="utf-8"))
                        blocks = data.get("blocks", [])
                        is_valid = bool(blocks and any(b.get("text", "").strip() for b in blocks))
                    elif source.suffix.lower() in (".html", ".htm"):
                        # –î–ª—è HTML —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç (–Ω–µ —Ç–æ–ª—å–∫–æ —Ç–µ–≥–∏)
                        content = source.read_text(encoding="utf-8")
                        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–≥–∏ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–∞
                        text_only = re.sub(r'<[^>]+>', '', content).strip()
                        # –ï—Å–ª–∏ HTML —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –≤ <pre> (–±–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã),
                        # –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TXT —Ñ–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω –ø–æ–∑–∂–µ
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ <pre> —Å —Ç–µ–∫—Å—Ç–æ–º
                        if re.search(r'<pre[^>]*>', content, re.IGNORECASE):
                            # –ï—Å–ª–∏ –µ—Å—Ç—å <pre>, –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                            has_structure = bool(re.search(r'<(h[1-6]|p|div|section|article|header|footer)[^>]*>', content, re.IGNORECASE))
                            # –ï—Å–ª–∏ –Ω–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ª—É—á—à–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ—Ç HTML –≤ –ø–æ–ª—å–∑—É TXT
                            if not has_structure:
                                is_valid = False  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π HTML –≤ –ø–æ–ª—å–∑—É TXT
                            else:
                                is_valid = bool(text_only)
                        else:
                            is_valid = bool(text_only)
                    
                    if is_valid:
                        epub_source = source
                        break
                    else:
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏—á–∏–Ω—É, –ø–æ—á–µ–º—É —Ñ–∞–π–ª –±—ã–ª –ø—Ä–æ–ø—É—â–µ–Ω
                        reason = "–ø—É—Å—Ç–æ–π"
                        if source.suffix.lower() == ".txt":
                            try:
                                content = source.read_text(encoding="utf-8").strip()
                                if not content:
                                    reason = "–ø—É—Å—Ç–æ–π"
                                elif len(content) < 50:
                                    reason = f"—Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)"
                                elif not any(c.isalpha() for c in content):
                                    reason = "—Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã/—Å–∏–º–≤–æ–ª—ã"
                            except:
                                reason = "–æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è"
                        print(f"‚ö†Ô∏è  –§–∞–π–ª {source.name} —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ {reason} - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                except Exception as e:
                    print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {source.name}: {e}")
                    continue
        
        if not epub_source:
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–∞–π–ª –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ EPUB")
            print(f"   –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {', '.join(str(s.name) for s in epub_sources)}")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
            for source in epub_sources:
                if source.exists():
                    try:
                        size = source.stat().st_size
                        print(f"   - {source.name}: —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ({size} –±–∞–π—Ç)")
                    except:
                        print(f"   - {source.name}: —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (—Ä–∞–∑–º–µ—Ä –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω)")
                else:
                    print(f"   - {source.name}: –Ω–µ –Ω–∞–π–¥–µ–Ω")
        else:
            print(f"üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è EPUB: {epub_source.name}")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º
            try:
                if epub_source.suffix.lower() == ".json":
                    import json
                    data = json.loads(epub_source.read_text(encoding="utf-8"))
                    blocks = data.get("blocks", [])
                    blocks_with_text = [b for b in blocks if b.get("text", "").strip()]
                    print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç {len(blocks)} –±–ª–æ–∫–æ–≤, –∏–∑ –Ω–∏—Ö {len(blocks_with_text)} —Å —Ç–µ–∫—Å—Ç–æ–º")
                elif epub_source.suffix.lower() == ".txt":
                    content = epub_source.read_text(encoding="utf-8")
                    lines = [l.strip() for l in content.splitlines() if l.strip()]
                    print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç {len(lines)} –Ω–µ–ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫, —Ä–∞–∑–º–µ—Ä: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ: {e}")
            template_epub = Path(args.epub_template)
            if not template_epub.is_absolute():
                if (here / template_epub).exists():
                    template_epub = here / template_epub
                elif (here / "sample.epub").exists():
                    template_epub = here / "sample.epub"
            
            if not template_epub.exists():
                print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —à–∞–±–ª–æ–Ω EPUB –Ω–µ –Ω–∞–π–¥–µ–Ω: {template_epub}")
            else:
                # –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è Windows (—É–±–∏—Ä–∞–µ–º –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã)
                safe_title = re.sub(r'[<>:"/\\|?*]', '_', args.title)
                safe_title = safe_title.replace(' ', '_')
                output_epub = outdir / f"{safe_title}.epub"
                epub_cmd = [
                    sys.executable,
                    str(here / "generate_epub.py"),
                    "--template", str(template_epub),
                    "--in", str(epub_source),
                    "--out", str(output_epub),
                    "--title", args.title,
                    "--max-chapter-size", str(args.epub_max_chapter_size),
                ]
                if args.author:
                    epub_cmd.extend(["--author", args.author])
                if args.cover_colors:
                    epub_cmd.extend(["--cover-colors", args.cover_colors])
                if args.epub_use_chapter_heads:
                    epub_cmd.append("--use-chapter-heads")
                
                if not run_cmd(epub_cmd, f"–≠—Ç–∞–ø 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è EPUB"):
                    return 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–∑–¥–∞–ª—Å—è –ª–∏ EPUB
                if output_epub.exists():
                    print("\n" + "=" * 80)
                    print("‚úÖ EPUB –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù!")
                    print("=" * 80)
                    print(f"  üìö {output_epub}")
                    print("=" * 80)
    
    print("\n" + "=" * 80)
    print("‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 80)
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ: {outdir}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    print("\n–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    for pattern in ["*.txt", "*.html", "*.json", "*.epub"]:
        files = list(outdir.glob(pattern))
        if files:
            print(f"\n{pattern}:")
            for f in sorted(files):
                print(f"  - {f.name}")
    
    return 0


if __name__ == '__main__':
    exit(main())
